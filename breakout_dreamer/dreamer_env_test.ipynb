{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atari_dreamerv3 import Atari\n",
    "import dreamerv3_wrappers as wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from post_processing_obs import blackout_obs_mode, crop_obs_mode\n",
    "from ram_modification_obs import ram_obs_modification_mode\n",
    "from gymnasium.core import ActionWrapper\n",
    "import random\n",
    "\n",
    "\n",
    "class PartialObservationWrapper(wrappers.CutomGymnasiumWrapper):\n",
    "    \"\"\"Custom wrapper that modifies observations\"\"\"\n",
    "    \n",
    "    def __init__(self, env, config):\n",
    "        super().__init__(env)\n",
    "        self.config = config\n",
    "        # Replace the _screen method from Atari env\n",
    "        self.env._screen = self._screen\n",
    "        self.manipulation = True # if false, returns original _screen behavior\n",
    "\n",
    "    def _manipulate_screen(self, array):\n",
    "        \"\"\"Modify the screen in buffer\"\"\"\n",
    "\n",
    "        # add a random probability to apply the modification\n",
    "        if np.random.rand() < self.config['prob']:\n",
    "            if self.config['type'] == 'blackout':\n",
    "                blackout_obs_mode(array, self.config['mode'])\n",
    "            elif self.config['type'] == 'crop':\n",
    "                crop_obs_mode(array, self.config['mode'])\n",
    "            elif self.config['type'] == 'ram':\n",
    "                array = ram_obs_modification_mode(self.env._env, self.config['mode'])\n",
    "    \n",
    "    def _screen(self, array):\n",
    "        self.env._ale.getScreenRGB(array)\n",
    "        if self.manipulation:\n",
    "            self._manipulate_screen(array)\n",
    "\n",
    "    # def render(self):\n",
    "    #     \"\"\"Override render to show the modified observation\"\"\"\n",
    "    #     if self.render_mode == \"rgb_array\":\n",
    "    #         # Get the current observation and apply our modification\n",
    "    #         obs = self.env.render()\n",
    "    #         if obs is not None:\n",
    "    #             return self.observation(obs)\n",
    "    #     return self.env.render()\n",
    "\n",
    "\n",
    "class ActionDependentStochasticityWrapper(ActionWrapper):\n",
    "    \"\"\"Wrapper that implements action dependent stochasticity in internal ale _env.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, config):\n",
    "        super().__init__(env)\n",
    "        self.prob = config['stochastic_action_prob']\n",
    "\n",
    "    def action(self, action):\n",
    "        if np.random.random() < self.prob:\n",
    "            # Choose random action\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            # Use predicted action\n",
    "            return action\n",
    "\n",
    "\n",
    "class ActionIndependentRandomStochasticityWrapper(ActionWrapper):\n",
    "    \"\"\"Wrapper that implements action independent random stochasticity in internal ale _env.\n",
    "\n",
    "    Note: Does not revert the score on screen.\n",
    "\n",
    "    Modes:\n",
    "       mode '0': No stochasticity.\n",
    "       mode '1': Block hit cancel - if a block is hit, the RAM is reverted to the previous state, effectively canceling the block hit.\n",
    "       mode '2': Block hit cancel (reward reverted) - if a block is hit, the RAM is reverted to the previous state, effectively canceling the block hit.\n",
    "       mode '3': Regenerate hit block - after a block is hit, with some probability, a randomly picked block RAM index is reverted to its original value, regenerating a block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, config):\n",
    "        super().__init__(env)\n",
    "        self.mode = config['mode']\n",
    "        self.prob = config['random_stochasticity_prob']\n",
    "\n",
    "    def _block_hit_cancel(self, action, cancel_reward=True, verbose=False):\n",
    "        \"\"\"\n",
    "        Takes affect if modified, in the next step.\n",
    "        If cancel_reward is True, the reward is set to 0 if block hit is cancelled.\n",
    "        \"\"\"\n",
    "        self.previous_ram_state = self.env.unwrapped.ale.getRAM()\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        current_ram_state = self.env.unwrapped.ale.getRAM()\n",
    "        if any(current_ram_state[:36] != self.original_ram_state[:36]):\n",
    "            changed_indices = [i for i in range(36) if current_ram_state[i] != self.previous_ram_state[i]]\n",
    "            if len(changed_indices) > 0 and random.random() < self.prob:\n",
    "                for i in changed_indices:\n",
    "                    self.env.unwrapped.ale.setRAM(i, self.previous_ram_state[i])\n",
    "                ## reset scores and lives to previous state (does not work)\n",
    "                # for i in range(81,91):\n",
    "                #     if verbose:\n",
    "                #         print(f\"resetting {i} to {self.previous_ram_state[i]} from {current_ram_state[i]}\")\n",
    "                #     self.env.unwrapped.ale.setRAM(i, self.previous_ram_state[i])\n",
    "                if verbose:\n",
    "                    print(f\"block hit cancelled\")\n",
    "                if cancel_reward:\n",
    "                    reward = 0.0\n",
    "                    if verbose:\n",
    "                        print(f\"reward reverted to 0\")\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def _regenerate_hit_block(self, action, verbose=False):\n",
    "        \"\"\"\n",
    "        Takes affect if modified, in the next step.\n",
    "        \"\"\"\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        current_ram_state = self.env.unwrapped.ale.getRAM()\n",
    "        # list of indices that changed\n",
    "        changed_indices = [i for i in range(36) if current_ram_state[i] != self.original_ram_state[i]]\n",
    "        # randomly choose a changed index and update its value to the original value\n",
    "        if len(changed_indices) > 0 and random.random() < self.prob:\n",
    "            random_index = random.choice(changed_indices)\n",
    "            self.env.unwrapped.ale.setRAM(random_index, self.original_ram_state[random_index])\n",
    "            if verbose:\n",
    "                print(f\"hit block regenerated\")\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        obs = self.env.reset(seed=seed, options=options)\n",
    "        self.original_ram_state = self.env.unwrapped.ale.getRAM()\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.mode == '0':\n",
    "            return self.env.step(action)\n",
    "        elif self.mode == '1':\n",
    "            return self._block_hit_cancel(action, cancel_reward=False, verbose=True)\n",
    "        elif self.mode == '2':\n",
    "            return self._block_hit_cancel(action, cancel_reward=True, verbose=True)\n",
    "        elif self.mode == '3':\n",
    "            return self._regenerate_hit_block(action)\n",
    "\n",
    "\n",
    "class ActionIndependentConceptDriftWrapper(wrappers.CutomGymnasiumWrapper):\n",
    "    \"\"\"\n",
    "    Wrapper that implements action independent concept drift in the environment.\n",
    "\n",
    "    Modes:\n",
    "        temporal_mode 'sudden': The environment concept (stochasticity type) switches suddenly after a fixed number of steps (temporal_threshold).\n",
    "        temporal_mode 'cyclic': The environment concept alternates cyclically every temporal_threshold steps between the original and secondary concept.\n",
    "\n",
    "    Args:\n",
    "        env: The environment to wrap.\n",
    "        config: Dictionary with keys:\n",
    "            - 'temporal_mode': 'sudden' or 'cyclic'\n",
    "            - 'temporal_threshold': Number of steps before switching concepts\n",
    "            - 'secondary_concept_type': The stochasticity type to switch to\n",
    "        StochasticEnv_instance: An instance that manages the stochastic environment and can update its type.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, config, StochasticEnv_instance):\n",
    "        super().__init__(env)\n",
    "        self._step_count = 0\n",
    "        self.current_cycle = 0\n",
    "        self.temporal_mode = config['temporal_mode']\n",
    "        self.temporal_threshold = config['temporal_threshold']\n",
    "        self.secondary_concept_type = config['secondary_concept_type']\n",
    "        self.StochasticEnv_instance = StochasticEnv_instance\n",
    "\n",
    "    def update_env_concept(self):\n",
    "        print(f\"updating env concept to stochasticity type: {self.secondary_concept_type}\")\n",
    "        if self.secondary_concept_type == 3:\n",
    "            raise RecursionError(\"`Concept drift` is not supported for secondary concept\")\n",
    "        if self.secondary_concept_type == 4:\n",
    "            raise ValueError(\"`Partial observation` is the initial concept\")\n",
    "        self.StochasticEnv_instance.type = self.secondary_concept_type\n",
    "        self.env = self.StochasticEnv_instance.get_env(self.env)\n",
    "\n",
    "    def revert_env_concept(self):\n",
    "        print(f\"reverting to original concept\")\n",
    "        if hasattr(self.env, 'manipulation'):\n",
    "            print(f\"reverting to original screen\")\n",
    "            self.env.manipulation = False\n",
    "        if hasattr(self.env, 'env'):\n",
    "            self.env = self.env.env # for type 5\n",
    "        else:\n",
    "            self.env._env = self.env._env.env # for type 1, 2\n",
    "\n",
    "    def get_cycle(self):\n",
    "        if self.temporal_mode == 'cyclic':\n",
    "            return 0 if (self._step_count // self.temporal_threshold) % 2 == 0 else 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        if self.temporal_mode == 'sudden':\n",
    "            if self._step_count == self.temporal_threshold - 1:\n",
    "                self.update_env_concept()\n",
    "\n",
    "        elif self.temporal_mode == 'cyclic': # currently bi-cyclic\n",
    "            _cycle = self.get_cycle()\n",
    "            if _cycle != self.current_cycle:\n",
    "                if self.current_cycle == 0:\n",
    "                    self.update_env_concept()\n",
    "                else:\n",
    "                    self.revert_env_concept()\n",
    "                self.current_cycle = _cycle\n",
    "\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self._step_count += 1\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, *args, **kwargs):\n",
    "        obs = self.env.reset(*args, **kwargs)\n",
    "        self._step_count = 0\n",
    "        return obs\n",
    "\n",
    "\n",
    "class StochasticEnv:\n",
    "    \"\"\"\n",
    "    Environment type docstrings:\n",
    "\n",
    "    0: Deterministic Env\n",
    "       - No stochasticity or partial observability applied.\n",
    "\n",
    "    1: Intrinsic Stochastic Env (action-dependent)\n",
    "       - Stochasticity is introduced based on the agent's actions.\n",
    "\n",
    "    2: Intrinsic Stochastic Env (action-independent-random, Aleatoric)\n",
    "       - Stochasticity is introduced independently of the agent's actions, e.g., random effects. # block not hit, regen\n",
    "\n",
    "    3: Intrinsic Stochastic Env (action-independent-concept-drift)\n",
    "       - Stochasticity is introduced by changing environment dynamics over time (concept drift). # within episode and combine sudden and cyclic\n",
    "\n",
    "    4: Partially observed Env (state-variable-different-repr)\n",
    "       - The environment state is partially observed by representing state variables differently.\n",
    "\n",
    "    5: Partially observed Env (state-variable-missing)\n",
    "       - The environment state is partially observed by omitting some state variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, type, config):\n",
    "        self.type = type\n",
    "        self.config = config\n",
    "\n",
    "    def get_env(self, env):\n",
    "        if self.type == 0:\n",
    "            raise NotImplementedError\n",
    "        elif self.type == 1:\n",
    "            env._env = ActionDependentStochasticityWrapper(env._env, config=self.config['intrinsic_stochasticity']['action_dependent'])\n",
    "            return env\n",
    "        elif self.type == 2:\n",
    "            env._env = ActionIndependentRandomStochasticityWrapper(env._env, config=self.config['intrinsic_stochasticity']['action_independent_random'])\n",
    "            return env\n",
    "        elif self.type == 3:\n",
    "            return ActionIndependentConceptDriftWrapper(env, config=self.config['intrinsic_stochasticity']['action_independent_concept_drift'], StochasticEnv_instance=self)\n",
    "        elif self.type == 4:\n",
    "            return env\n",
    "        elif self.type == 5:\n",
    "            return PartialObservationWrapper(env, config=self.config['partial_observation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_frame(obs, label=''):\n",
    "    \"\"\"Plot a frame without going into interactive mode\"\"\"\n",
    "    # Create a new figure with non-interactive backend for this plot\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(obs)\n",
    "    ax.set_title(f'Observation {label}')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)  # Don't block, just display\n",
    "    plt.close()  # Close the figure to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Atari(\n",
    "            'Breakout',\n",
    "            4,\n",
    "            [64, 64],\n",
    "            gray=False,\n",
    "            noops=0,\n",
    "            lives='unused',\n",
    "            sticky=False,\n",
    "            actions='needed',\n",
    "            resize='opencv',\n",
    "            seed=0,\n",
    "        )\n",
    "\n",
    "stochasticity_config = {\n",
    "    'intrinsic_stochasticity': {\n",
    "        'action_dependent': {\n",
    "            'stochastic_action_prob': 1.0,\n",
    "            },\n",
    "        'action_independent_random': {\n",
    "            'mode': '2',\n",
    "            'random_stochasticity_prob': 0.25, # mode 3: keep around 0.0005\n",
    "        },\n",
    "        'action_independent_concept_drift': {\n",
    "            'temporal_mode': 'cyclic', # 'sudden' or 'cyclic'\n",
    "            'temporal_threshold': 5,\n",
    "            'secondary_concept_type': 1,\n",
    "        },\n",
    "    },\n",
    "    'partial_observation': {\n",
    "            'type': 'blackout', # 'blackout' or 'crop' or 'ram'\n",
    "            'mode': '2', # mode 1 in ram is buggy\n",
    "            'prob': 1.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "stochasticity_wrapper = StochasticEnv(type=3, config=stochasticity_config)\n",
    "env = stochasticity_wrapper.get_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = wrappers.OneHotAction(env)\n",
    "env = wrappers.TimeLimit(env, duration=108000)\n",
    "env = wrappers.SelectAction(env, key=\"action\")\n",
    "env = wrappers.UUID(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state.keys()\n",
    "plot_frame(state['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state, reward, is_last, _ = env.step({'action': np.array([0, 1 , 0, 0])})\n",
    "print(env.env.env.env.env._step_count)\n",
    "plot_frame(state['image'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
